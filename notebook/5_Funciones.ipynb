{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933f1823",
   "metadata": {},
   "source": [
    "# INE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a65d0e",
   "metadata": {},
   "source": [
    "La función 'leer_archivo_rango_periodo' lee un archivo CSV, crea una copia del DataFrame original, filtra las filas que contienen un periodo específico en la columna 'Periodo', reinicia los índices y devuelve el DataFrame resultante. Esto facilita la obtención de datos específicos para un periodo dado desde un archivo CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebb25992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer CSV\n",
    "def leer_archivo_rango_periodo(ruta_archivo, periodo):\n",
    "    \n",
    "    #leer archivo CSV\n",
    "    ine_original = pd.read_csv(ruta_archivo, encoding='latin1',sep=\"\\t\")\n",
    "    \n",
    "    #crear copia del DF original\n",
    "    ine_copia= ine_original.copy()\n",
    "    \n",
    "    #FIltrar el DataFrame para incluir solo las filas que contienen el periodo deseado\n",
    "    ine_filtrado= ine_copia[ine_copia['Periodo'].str.contains(periodo)]\n",
    "    \n",
    "    ine_filtrado = ine_filtrado.reset_index(drop=True)\n",
    "    \n",
    "    return ine_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5498a",
   "metadata": {},
   "source": [
    "La función 'procesar_columnas' renombra algunas columnas específicas de un DataFrame, utilizando un diccionario para asignar nombres más claros y legibles. Luego, reinicia los índices del DataFrame y devuelve el resultado procesado. Esto facilita la limpieza y clarificación de los nombres de columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af3d6c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_columnas(df):\n",
    "\n",
    "    column_rename_dict = {\n",
    "        'ï»¿Totales Territoriales': 'Totales_Territoriales',\n",
    "        'Comunidades y Ciudades AutÃ³nomas': 'Comunidades_Ciudades_Autonomas',\n",
    "        'Provincias': 'Provincia',\n",
    "        'Viajeros y pernoctaciones': 'Viajeros_Pernoctaciones',\n",
    "        'Residencia: Nivel 1': 'Residencia_Nivel_1',\n",
    "        'Residencia: Nivel 2': 'Residencia_Nivel_2',\n",
    "        'Periodo': 'Periodo',\n",
    "        'Total': 'Total'\n",
    "    }\n",
    "\n",
    "    df.rename(columns=column_rename_dict, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be2482",
   "metadata": {},
   "source": [
    "La función 'actualizar_valor_en_fila' toma un DataFrame, el número de fila, el nombre de la columna y el valor a restar. Luego, actualiza el valor en la fila y columna especificadas con el resultado de la resta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1e368a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_valor_en_fila(dataframe, fila, columna, resta_resultado):\n",
    "    dataframe.loc[fila, columna] = resta_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e08e79",
   "metadata": {},
   "source": [
    "# AEMET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948ac55",
   "metadata": {},
   "source": [
    "La función 'obtener_url_datos' simplifica la obtención de datos climáticos diarios para un periodo de 10 años al construir dinámicamente la URL con las fechas proporcionadas y gestionar la autenticación mediante la clave de API almacenada, mejorando la modularidad y legibilidad del código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a39a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_url_datos(fecha_inicio, fecha_fin):\n",
    "    base_url = 'https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos/'\n",
    "    parametros = f'fechaini/{fecha_inicio}/fechafin/{fecha_fin}/todasestaciones'\n",
    "    url = f'{base_url}{parametros}'\n",
    "    \n",
    "    with open('../api.txt', 'r') as file:\n",
    "        api_key = file.read().strip()\n",
    "\n",
    "    response = requests.get(url, headers={'api_key': api_key})\n",
    "    data = response.json()\n",
    "\n",
    "    if data['estado'] == 200:\n",
    "        return data['datos']\n",
    "    \n",
    "    else:\n",
    "        print(f\"Error en la solicitud: {data['descripcion']}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b25b4",
   "metadata": {},
   "source": [
    "La siguiente función, se crea para realizar diversas transformaciones en las columnas especificadas y devuelve un nuevo DataFrame con los resultados procesados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7876272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_mes(df_mes, columnas_procesar):\n",
    "\n",
    "    for col in columnas_procesar:\n",
    "        df_mes[col] = df_mes[col].str.replace(',', '.').replace('Acum', np.nan).replace('Ip', np.nan).astype(float)\n",
    "\n",
    "    df_mes['fecha'] = pd.to_datetime(df_mes['fecha']).dt.to_period('M')\n",
    "    \n",
    "    df_media_mes = df_mes.groupby('provincia').agg({'fecha': 'first', \n",
    "                                                    **{col: 'mean' for col in columnas_procesar}}).reset_index()\n",
    "\n",
    "    df_media_mes = df_media_mes.rename(columns={'fecha': 'periodo', \n",
    "                                                **{col: f'media_{col}' for col in columnas_procesar}})\n",
    "    \n",
    "    try:\n",
    "        df_media_mes = df_media_mes[~df_media_mes['provincia'].isin(['CEUTA', 'MELILLA'])].reset_index(drop=True)\n",
    "    except KeyError:\n",
    "        pass  \n",
    "\n",
    "    df_media_mes.columns = df_media_mes.columns.str.capitalize()\n",
    "\n",
    "    df_media_mes['Provincia'] = df_media_mes['Provincia'].apply(lambda x: x.capitalize())\n",
    "\n",
    "    return df_media_mes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d04fc0",
   "metadata": {},
   "source": [
    "La función 'procesar_datos_mes' toma una URL y una lista de columnas de interés como entrada, realiza una solicitud GET a esa URL para obtener datos de la API, y luego procesa esos datos utilizando la función 'procesar_mes':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eeb7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_datos_mes(url, columnas_interes):\n",
    "    \n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        datos = response.json()\n",
    "        df = pd.DataFrame(datos)\n",
    "        df = df[columnas_interes]\n",
    "        df_procesado = procesar_mes(df)\n",
    "\n",
    "        return df_procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831a861",
   "metadata": {},
   "source": [
    "# CONEXIÓN MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "590864f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_cadena_conexion(usuario, ruta_archivo_contraseña, host, puerto):\n",
    "    with open(ruta_archivo_contraseña, 'r') as file:\n",
    "        contraseña = file.read().strip()\n",
    "\n",
    "    cadena_conexion = f'mysql+mysqlconnector://{usuario}:{contraseña}@{host}:{puerto}'\n",
    "\n",
    "    return cadena_conexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8fee86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_base_de_datos(cadena_conexion, nombre_bd):\n",
    "    engine = create_engine(cadena_conexion)\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(f\"CREATE DATABASE IF NOT EXISTS {nombre_bd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8120a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_csv_a_mysql(ruta_csv, cadena_conexion, nombre_tabla, nombre_bd):\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(ruta_csv)\n",
    "        \n",
    "        engine = create_engine(cadena_conexion)\n",
    "        \n",
    "        with engine.connect() as connection:\n",
    "            connection.execute(f\"USE {nombre_bd}\")\n",
    "        \n",
    "        df.to_sql(nombre_tabla, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "        print(f\"Datos cargados en la tabla {nombre_tabla} con éxito.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar los datos en MySQL: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clima",
   "language": "python",
   "name": "clima"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
