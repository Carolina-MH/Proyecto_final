{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e6672c",
   "metadata": {},
   "source": [
    "# INE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db6f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leer csv\n",
    "def leer_archivo_rango_periodo(ruta_archivo, periodo):\n",
    "    \n",
    "    #leer archivo CSV\n",
    "    ine_original = pd.read_csv(ruta_archivo, encoding='latin1',sep=\"\\t\")\n",
    "    \n",
    "    #crear copia del DF original\n",
    "    ine_copia= ine_original.copy()\n",
    "    \n",
    "    #FIltrar el DataFrame para incluir solo las filas que contienen el periodo deseado\n",
    "    ine_filtrado= ine_copia[ine_copia['Periodo'].str.contains(periodo)]\n",
    "    \n",
    "    ine_filtrado = ine_filtrado.reset_index(drop=True)\n",
    "    \n",
    "    return ine_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ce0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpieza de datos\n",
    "def procesar_ine_data(df):\n",
    "    \n",
    "    column_rename_dict = {'ï»¿Totales Territoriales': 'Totales_Territoriales',\n",
    "                      'Comunidades y Ciudades AutÃ³nomas': 'Comunidades_Ciudades_Autonomas',\n",
    "                      'Provincias': 'Provincias',\n",
    "                      'Viajeros y pernoctaciones': 'Viajeros_Pernoctaciones',\n",
    "                      'Residencia: Nivel 1': 'Residencia_Nivel_1',\n",
    "                      'Residencia: Nivel 2': 'Residencia_Nivel_2',\n",
    "                      'Periodo': 'Periodo',\n",
    "                      'Total': 'Total'}\n",
    "    \n",
    "    # Renombro las columnas usando el diccionario\n",
    "    df.rename(columns=column_rename_dict, inplace=True)\n",
    "    \n",
    "    #Reseteo el indice\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Filtro filas para obtener el DataFrame de Viajeros\n",
    "    viajeros_df = df[df['Viajeros_Pernoctaciones'] == 'Viajero']\n",
    "\n",
    "    # Filtro filas para obtener el DataFrame de Pernoctaciones\n",
    "    pernoctaciones_df = df[df['Viajeros_Pernoctaciones'] == 'Pernoctaciones']\n",
    "\n",
    "    # Reseteo los índices para ambos DataFrames\n",
    "    viajeros_df.reset_index(drop=True, inplace=True)\n",
    "    pernoctaciones_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return viajeros_df, pernoctaciones_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2aa9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_viajeros(df):\n",
    "    \n",
    "    #'pivot_table' para reestructurar los datos. \n",
    "    viajeros= df.pivot_table(index= 'Provincias', columns= ('Periodo','Residencia_Nivel_2'), values= 'Total', aggfunc= 'sum')\n",
    "    \n",
    "    #Estandarizo el índice para que también pueda relacionarlo con el resto de fuentes a estudiar\n",
    "    correccion_provincias = {'01 Araba/Ãlava': 'ARABA/ALAVA', \n",
    "                       '02 Albacete': 'ALBACETE', \n",
    "                       '03 Alicante/Alacant': 'ALICANTE', \n",
    "                       '04 AlmerÃ­a': 'ALMERIA',\n",
    "                       '05 Ãvila': 'AVILA',\n",
    "                       '06 Badajoz': 'BADAJOZ',\n",
    "                       '07 Balears, Illes': 'ILLES BALEARS',\n",
    "                       '08 Barcelona': 'BARCELONA',\n",
    "                       '09 Burgos': 'BURGOS',\n",
    "                       '10 CÃ¡ceres': 'CACERES',\n",
    "                       '11 CÃ¡diz': 'CADIZ',\n",
    "                       '12 CastellÃ³n/CastellÃ³': 'CASTELLON',\n",
    "                       '13 Ciudad Real': 'CIUDAD REAL',\n",
    "                       '14 CÃ³rdoba': 'CORDOBA',\n",
    "                       '15 CoruÃ±a, A': 'A CORUÑA',\n",
    "                       '16 Cuenca': 'CUENCA',\n",
    "                       '17 Girona': 'GIRONA',\n",
    "                       '18 Granada': 'GRANADA',\n",
    "                       '19 Guadalajara': 'GUADALAJARA',\n",
    "                       '20 Gipuzkoa': 'GIPUZKOA',\n",
    "                       '21 Huelva': 'HUELVA',\n",
    "                       '22 Huesca': 'HUESCA',\n",
    "                       '23 JaÃ©n': 'JAEN',\n",
    "                       '24 LeÃ³n': 'LEON',\n",
    "                       '25 Lleida': 'LLEIDA',\n",
    "                       '26 Rioja, La': 'LA RIOJA',\n",
    "                       '27 Lugo': 'LUGO',\n",
    "                       '28 Madrid': 'MADRID',\n",
    "                       '29 MÃ¡laga': 'MALAGA',\n",
    "                       '30 Murcia': 'MURCIA',\n",
    "                       '31 Navarra':'NAVARRA',\n",
    "                       '32 Ourense': 'OURENSE',\n",
    "                       '33 Asturias': 'ASTURIAS',\n",
    "                       '34 Palencia': 'PALENCIA',\n",
    "                       '35 Palmas, Las': 'LAS PALMAS',\n",
    "                       '36 Pontevedra': 'PONTEVEDRA',\n",
    "                       '37 Salamanca':'SALAMANCA' ,\n",
    "                       '38 Santa Cruz de Tenerife': 'STA. CRUZ DE TENERIFE',\n",
    "                       '39 Cantabria': 'CANTABRIA',\n",
    "                       '40 Segovia': 'SEGOVIA',\n",
    "                       '41 Sevilla': 'SEVILLA',\n",
    "                       '42 Soria': 'SORIA',\n",
    "                       '43 Tarragona': 'TARRAGONA',\n",
    "                       '44 Teruel': 'TERUEL',\n",
    "                       '45 Toledo': 'TOLEDO',\n",
    "                       '46 Valencia/ValÃ¨ncia': 'VALENCIA',\n",
    "                       '47 Valladolid': 'VALLADOLID',\n",
    "                       '48 Bizkaia': 'BIZKAIA',\n",
    "                       '49 Zamora': 'ZAMORA',\n",
    "                       '50 Zaragoza': 'ZARAGOZA'}\n",
    "    #Corrijo el índice. Recurriré 'map' para aplicar una función a cada elemento del índice de este DF.\n",
    "    viajeros.index =viajeros.index.map(correccion_provincias)\n",
    "    \n",
    "    #Primero me aseguro que 'viajeros' tenga el mismo índice antes de ordenarlo\n",
    "    viajeros.reset_index(inplace=True)\n",
    "    viajeros = viajeros.set_index('Provincias')\n",
    "    \n",
    "    #Establezco el índice para ordenarlos por orden alfabético:\n",
    "    viajeros = viajeros.sort_index()\n",
    "    \n",
    "    #Ajusto los nombre de las columnas del segundo nivel. Accedo también al segundo nivel que es donde se encuentra.\n",
    "    viajeros.columns = viajeros.columns.set_levels(viajeros.columns.levels[1].str.replace('Residentes en EspaÃ±a', 'Residentes en Espana'), level=1)\n",
    "    \n",
    "    #A continuación junto el primer nivel y el segundo para poder exportarlo correctamente a la Base de Datos:\n",
    "    viajeros.columns = [e[0]+'_'+e[1] for e in viajeros.columns]\n",
    "    \n",
    "    return viajeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29385406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_pernoctaciones(df, sufijo):\n",
    "    \n",
    "    #'pivot_table' para reestructurar los datos. \n",
    "    pernoctaciones= df.pivot_table(index= 'Provincias', columns= ('Periodo','Residencia_Nivel_2'), values= 'Total', aggfunc= 'sum')\n",
    "    \n",
    "    #Estandarizo el índice para que también pueda relacionarlo con el resto de fuentes a estudiar\n",
    "    correccion_provincias = {'01 Araba/Ãlava': 'ARABA/ALAVA', \n",
    "                       '02 Albacete': 'ALBACETE', \n",
    "                       '03 Alicante/Alacant': 'ALICANTE', \n",
    "                       '04 AlmerÃ­a': 'ALMERIA',\n",
    "                       '05 Ãvila': 'AVILA',\n",
    "                       '06 Badajoz': 'BADAJOZ',\n",
    "                       '07 Balears, Illes': 'ILLES BALEARS',\n",
    "                       '08 Barcelona': 'BARCELONA',\n",
    "                       '09 Burgos': 'BURGOS',\n",
    "                       '10 CÃ¡ceres': 'CACERES',\n",
    "                       '11 CÃ¡diz': 'CADIZ',\n",
    "                       '12 CastellÃ³n/CastellÃ³': 'CASTELLON',\n",
    "                       '13 Ciudad Real': 'CIUDAD REAL',\n",
    "                       '14 CÃ³rdoba': 'CORDOBA',\n",
    "                       '15 CoruÃ±a, A': 'A CORUÑA',\n",
    "                       '16 Cuenca': 'CUENCA',\n",
    "                       '17 Girona': 'GIRONA',\n",
    "                       '18 Granada': 'GRANADA',\n",
    "                       '19 Guadalajara': 'GUADALAJARA',\n",
    "                       '20 Gipuzkoa': 'GIPUZKOA',\n",
    "                       '21 Huelva': 'HUELVA',\n",
    "                       '22 Huesca': 'HUESCA',\n",
    "                       '23 JaÃ©n': 'JAEN',\n",
    "                       '24 LeÃ³n': 'LEON',\n",
    "                       '25 Lleida': 'LLEIDA',\n",
    "                       '26 Rioja, La': 'LA RIOJA',\n",
    "                       '27 Lugo': 'LUGO',\n",
    "                       '28 Madrid': 'MADRID',\n",
    "                       '29 MÃ¡laga': 'MALAGA',\n",
    "                       '30 Murcia': 'MURCIA',\n",
    "                       '31 Navarra':'NAVARRA',\n",
    "                       '32 Ourense': 'OURENSE',\n",
    "                       '33 Asturias': 'ASTURIAS',\n",
    "                       '34 Palencia': 'PALENCIA',\n",
    "                       '35 Palmas, Las': 'LAS PALMAS',\n",
    "                       '36 Pontevedra': 'PONTEVEDRA',\n",
    "                       '37 Salamanca':'SALAMANCA' ,\n",
    "                       '38 Santa Cruz de Tenerife': 'STA. CRUZ DE TENERIFE',\n",
    "                       '39 Cantabria': 'CANTABRIA',\n",
    "                       '40 Segovia': 'SEGOVIA',\n",
    "                       '41 Sevilla': 'SEVILLA',\n",
    "                       '42 Soria': 'SORIA',\n",
    "                       '43 Tarragona': 'TARRAGONA',\n",
    "                       '44 Teruel': 'TERUEL',\n",
    "                       '45 Toledo': 'TOLEDO',\n",
    "                       '46 Valencia/ValÃ¨ncia': 'VALENCIA',\n",
    "                       '47 Valladolid': 'VALLADOLID',\n",
    "                       '48 Bizkaia': 'BIZKAIA',\n",
    "                       '49 Zamora': 'ZAMORA',\n",
    "                       '50 Zaragoza': 'ZARAGOZA'}\n",
    "    \n",
    "    #Corrijo el índice. Recurriré 'map' para aplicar una función a cada elemento del índice de este DF.\n",
    "    pernoctaciones.index =pernoctaciones.index.map(correccion_provincias)\n",
    "    \n",
    "    #Primero me aseguro que 'viajeros' tenga el mismo índice antes de ordenarlo\n",
    "    pernoctaciones.reset_index(inplace=True)\n",
    "    pernoctaciones = pernoctaciones.set_index('Provincias')\n",
    "    \n",
    "    #Establezco el índice para ordenarlos por orden alfabético:\n",
    "    pernoctaciones = pernoctaciones.sort_index()\n",
    "    \n",
    "    #Ajusto los nombre de las columnas del segundo nivel. Accedo también al segundo nivel que es donde se encuentra.\n",
    "    pernoctaciones.columns = pernoctaciones.columns.set_levels(pernoctaciones.columns.levels[1].str.replace('Residentes en EspaÃ±a', 'Residentes en Espana'), level=1)\n",
    "    \n",
    "    #A continuación junto el primer nivel y el segundo para poder exportarlo correctamente a la Base de Datos:\n",
    "    pernoctaciones.columns = [e[0]+'_'+e[1]+ '_'for e in pernoctaciones.columns]    \n",
    "\n",
    "    return pernoctaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce10a618",
   "metadata": {},
   "source": [
    "# AEMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa3be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_encabezado_api(api_file_path='../api.txt'):\n",
    "# utilizo un token de autorización guardado en un archivo para acceder a la API de manera segura y obtener datos climáticos actualizados\n",
    "    aemet = os.getenv(\"api\")\n",
    "\n",
    "    with open(api_file_path, 'r') as file: \n",
    "    \n",
    "        token = file.read()\n",
    "\n",
    "    header = {'Authorization': f\"password {token}\"}\n",
    "    \n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cf91eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solicitud_get(url, api_file_path='../api.txt'):\n",
    "    \n",
    "    header = obtener_encabezado_api(api_file_path)\n",
    "\n",
    "    querystring = {\"api_key\": header['Authorization'].split()[-1]}\n",
    "\n",
    "    headers = {\n",
    "        'cache-control': \"no-cache\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "    # Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        # Si la solicitud no fue exitosa, imprimir el código de estado y texto de la respuesta\n",
    "        print(f\"Error en la solicitud. Código de estado: {response.status_code}, Mensaje: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c33cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_datos_mes(url, columnas_interes):\n",
    "    # Obtener los datos de la API\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "    if response.status_code == 200:\n",
    "        # Convertir la respuesta JSON a un DataFrame\n",
    "        datos = response.json()\n",
    "        df = pd.DataFrame(datos)\n",
    "        # Seleccionar columnas de interés\n",
    "        df = df[columnas_interes]\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48a3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpieza de datos para cada mes\n",
    "\n",
    "def procesar_mes(df_mes):\n",
    "    # Reemplazar comas por puntos y convertir las columnas numéricas a tipo float\n",
    "    df_mes['tmed'] = df_mes['tmed'].str.replace(',', '.').astype(float)\n",
    "    df_mes['prec'] = df_mes['prec'].replace('Acum', np.nan)\n",
    "    df_mes['prec'] = df_mes['prec'].str.replace(',', '.').replace('Ip', np.nan).astype(float)\n",
    "    df_mes['sol'] = df_mes['sol'].str.replace(',', '.').astype(float)\n",
    "    df_mes['tmin'] = df_mes['tmin'].str.replace(',', '.').astype(float)\n",
    "    df_mes['tmax'] = df_mes['tmax'].str.replace(',', '.').astype(float)\n",
    "    \n",
    "    # Convertir la columna \"fecha\" en datetime\n",
    "    df_mes['fecha'] = pd.to_datetime(df_mes['fecha'])\n",
    "    \n",
    "    # Agrupar por provincia y calcular la media de cada columna\n",
    "    df_media_mes = df_mes.groupby('provincia').agg({\n",
    "        'tmed': 'mean',\n",
    "        'prec': 'mean',\n",
    "        'sol': 'mean',\n",
    "        'tmin': 'mean',\n",
    "        'tmax': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Renombrar las columnas para mayor claridad\n",
    "    df_media_mes = df_media_mes.rename(columns={\n",
    "        'tmed': 'media_tmed',\n",
    "        'prec': 'media_prec',\n",
    "        'sol': 'media_sol',\n",
    "        'tmin': 'media_tmin',\n",
    "        'tmax': 'media_tmax'\n",
    "    })\n",
    "    # Eliminar las filas correspondientes a 'CEUTA' y 'MELILLA'\n",
    "    indices_a_eliminar = df_media_mes[df_media_mes['provincia'].isin(['CEUTA', 'MELILLA'])].index\n",
    "    df_media_mes = df_media_mes.drop(indices_a_eliminar).reset_index(drop=True)\n",
    "    \n",
    "    return df_media_mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c782247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#función para añadir aña y mes en los DF\n",
    "\n",
    "def procesar_y_setear_mes(df, año, mes):\n",
    "    df = procesar_mes(df)\n",
    "    df['año'] = [año] * len(df)\n",
    "    df['mes'] = [mes] * len(df)\n",
    "    df.set_index('provincia', inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10862040",
   "metadata": {},
   "source": [
    "# CONEXIÓN SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "793daf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_cadena_conexion(usuario, ruta_archivo_contraseña, host, puerto, nombre_bd):\n",
    "\n",
    "    with open(ruta_archivo_contraseña, 'r') as file:\n",
    "        contraseña = file.read().strip()\n",
    "\n",
    "    # Cadena de conexión\n",
    "    cadena_conexion = f'mysql+mysqlconnector://{usuario}:{contraseña}@{host}:{puerto}/{nombre_bd}'\n",
    "\n",
    "    return cadena_conexion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7faabeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_csv_a_mysql(ruta_csv, cadena_conexion, nombre_tabla):\n",
    "\n",
    "    try:\n",
    "        # Cargar el CSV en un DataFrame\n",
    "        df = pd.read_csv(ruta_csv)\n",
    "        \n",
    "        # Crear el motor de conexión\n",
    "        engine = create_engine(cadena_conexion)\n",
    "        \n",
    "        # Cargar el DataFrame en la base de datos\n",
    "        df.to_sql(nombre_tabla, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "        print(f\"Datos cargados en la tabla {nombre_tabla} con éxito.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar los datos en MySQL: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clase",
   "language": "python",
   "name": "clase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
